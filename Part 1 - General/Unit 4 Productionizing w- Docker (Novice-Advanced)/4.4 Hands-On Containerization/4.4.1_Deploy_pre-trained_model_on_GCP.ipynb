{"cells":[{"cell_type":"markdown","source":["# NOTE\n","This notebook, and all others involving Docker, cannot be run on Colab, and should be run either on your local machine or on your Vertex AI Workbench instance by cloning the [til-24-curriculum repository from GitHub](https://github.com/TIL-24/til-24-curriculum/)."],"metadata":{"id":"jaT7oMrY28kB"}},{"cell_type":"markdown","metadata":{"id":"VxwFkrDLaW_k"},"source":["# Deploying a Pre-Trained Model with FastAPI and Docker on GCP\n","\n","This tutorial demonstrates how to expose a pre-trained PyTorch model as a REST API using FastAPI, containerize the application with Docker on Google Cloud, and test the endpoint using Python's `requests` library."]},{"cell_type":"markdown","metadata":{"vscode":{"languageId":"plaintext"},"id":"yuDZ8nrZaW_m"},"source":["### Step 1: Prepare Your PyTorch Model\n","\n","First, make sure you have your PyTorch model ready. For this example, we'll use the ResNet model. The ResNet model, short for Residual Network, is a type of convolutional neural network (CNN). It was trained on the ImageNet dataset, a large visual database containing over 14 million images categorized into 1,000 classes. ResNet models are capable of predicting the class of an image among these categories, demonstrating impressive accuracy and efficiency in image classification tasks."]},{"cell_type":"markdown","metadata":{"vscode":{"languageId":"plaintext"},"id":"8EyXK2j6aW_m"},"source":["\n","### Step 2: Create the FastAPI Application\n","\n","Create a new Python script named `app.py` that will serve as our FastAPI application. This application will handle API requests and return predictions from the PyTorch model.\n","\n","```python\n","from fastapi import FastAPI, File, UploadFile\n","from fastapi.responses import JSONResponse\n","import torch\n","from torchvision import models, transforms\n","from PIL import Image\n","import io\n","\n","app = FastAPI()\n","\n","# Load the pre-trained model\n","model = models.resnet18(pretrained=True)\n","model.eval()  # Set model to evaluation mode\n","\n","# Define image transformations\n","transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","@app.post(\"/predict/\")\n","async def predict(file: UploadFile = File(...)):\n","    image_data = await file.read()\n","    image = Image.open(io.BytesIO(image_data))\n","    image = transform(image)\n","    image = image.unsqueeze(0)  # Add batch dimension\n","\n","    with torch.no_grad():\n","        output = model(image)\n","        predicted_index = output.argmax(1).item()\n","    \n","    return JSONResponse(content={\"predicted_class\": predicted_index})\n"]},{"cell_type":"markdown","metadata":{"vscode":{"languageId":"plaintext"},"id":"d1iPIbHZaW_m"},"source":["### Step 3: Dockerize the Application\n","Create a Dockerfile in the same directory as your `app.py`:\n","\n","```Dockerfile\n","# Use an official PyTorch runtime as a parent image\n","FROM pytorch/pytorch:1.9.0-cuda11.1-cudnn8-runtime\n","\n","# Install pip packages\n","RUN pip install fastapi uvicorn Pillow torchvision python-multipart\n","\n","# Set the working directory\n","WORKDIR /app\n","\n","# Copy the local directory contents to the container\n","COPY . /app\n","\n","# Command to run the app using uvicorn\n","CMD [\"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n","```"]},{"cell_type":"markdown","metadata":{"vscode":{"languageId":"plaintext"},"id":"f_6F0WwnaW_m"},"source":["### Step 4: Build and Run the Docker Container\n","Open a terminal window in JupyterLab and run the following command to build the Docker image and wait for the `Successfully tagged demo-model:latest` message.\n","\n","<img src=\"https://lh3.googleusercontent.com/d/18onL8nKzNOQ7yJwsXhtN-Azc2vudc7dJ\" alt=\"drawing\" width=\"600\"/>\n","\n","```bash\n","docker build -t demo-model .\n","```"]},{"cell_type":"markdown","metadata":{"vscode":{"languageId":"plaintext"},"id":"o56Y4HmPaW_n"},"source":["<img src=\"https://lh3.googleusercontent.com/d/1NU9DAnhWysP9wh6-mOuj0F5ZzSdUl-Jj\" alt=\"drawing\" width=\"800\"/>"]},{"cell_type":"markdown","metadata":{"vscode":{"languageId":"plaintext"},"id":"VwJHQIb7aW_n"},"source":["Run the Docker container"]},{"cell_type":"markdown","metadata":{"vscode":{"languageId":"plaintext"},"id":"izXZgcmdaW_n"},"source":["```bash\n","docker run -p 8000:8000 demo-model\n","```"]},{"cell_type":"markdown","metadata":{"vscode":{"languageId":"plaintext"},"id":"miuuZyN0aW_n"},"source":["\n","<img src=\"https://lh3.googleusercontent.com/d/1_efTzPvazat3b1WU1Pmueplqj5NwGLRe\" alt=\"drawing\" width=\"1000\"/>"]},{"cell_type":"markdown","metadata":{"vscode":{"languageId":"plaintext"},"id":"TRY_4JSYaW_n"},"source":["### Step 5: Test the API Using Python Requests\n","With the Docker container running, create a Python notebook `test_api.ipynb` to send an image to the FastAPI application and receive a prediction:\n","```Python\n","import requests\n","\n","# URL of the FastAPI endpoint\n","url = 'http://localhost:8000/predict/'\n","\n","# Path to the image file\n","file_path = '/home/jupyter/imgs/cat.jpeg'\n","\n","# Open the image file in binary mode\n","with open(file_path, 'rb') as f:\n","    # Prepare the request payload as a dictionary\n","    files = {'file': (file_path, f, 'image/jpeg')}\n","    \n","    # Send the POST request\n","    response = requests.post(url, files=files)\n","\n","# Print the response\n","print(response.json())\n","```"]},{"cell_type":"markdown","metadata":{"vscode":{"languageId":"plaintext"},"id":"9_5r9B5yaW_o"},"source":["<html>\n","<body>\n","\n","<p>\n","  <img src=\"https://lh3.googleusercontent.com/d/1X_uWg8ADU3kEgxe-BKsEvAu3Oy54VJHU\" alt=\"drawing\" width=\"400\"/>\n","  <img src=\"https://lh3.googleusercontent.com/d/19mLZnbfLTbGiCxZt_U5Vo8x3iIOIm9D-\" alt=\"drawing\" width=\"500\"/>\n","</p>\n","\n","</body>\n","</html>\n"]},{"cell_type":"markdown","metadata":{"vscode":{"languageId":"plaintext"},"id":"l_RmmeddaW_o"},"source":["To interpret the predicted class from a ResNet model trained on the ImageNet dataset, we can refer to the ImageNet class index [here](https://deeplearning.cms.waikato.ac.nz/user-guide/class-maps/IMAGENET/) , which maps each class index to a human-readable label. When the model predicts an integer class index, this index corresponds to a specific label in the ImageNet class list.\n","\n","For example, if the model outputs a prediction of `281`, you can look up this index in the ImageNet label file to find that it corresponds to the class \"tabby,tabby cat\".\n","\n","<img src=\"https://lh3.googleusercontent.com/d/1bhhPWBdxEvP-qKGJpA9m-iWFGOyhufcS\" alt=\"drawing\" width=\"550\"/>"]},{"cell_type":"markdown","metadata":{"vscode":{"languageId":"plaintext"},"id":"2y4vq8uiaW_o"},"source":["<html>\n","<body>\n","\n","<p>\n","  <img src=\"https://lh3.googleusercontent.com/d/1VeGaNxgHgf65nSHHZ4FMLAvi16zEGCck\" alt=\"drawing\" width=\"400\"/>\n","  <img src=\"https://lh3.googleusercontent.com/d/1YF8B1V6k4xaRm94N9u7r8L4YWshaa0Q_\" alt=\"drawing\" width=\"600\"/>\n","  <img src=\"https://lh3.googleusercontent.com/d/1G8M9dmiXcX1U-rd7iA24T5wEQDmnsEkc\" alt=\"drawing\" width=\"400\"/>\n","</p>\n","\n","</body>\n","</html>\n"]},{"cell_type":"code","source":[],"metadata":{"id":"pKDCfkspvr9-"},"execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[{"file_id":"1q9i-xBrWC1zuuo_wUWXBT6ZFEEFtUYfW","timestamp":1715050602031}]}},"nbformat":4,"nbformat_minor":0}